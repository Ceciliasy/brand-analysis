{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2324716, 300)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2010\n",
    "input_dir = '/mnt/HDD/embedding/'\n",
    "output_dir = '/mnt/HDD/w2c/'\n",
    "file = \"twitter_vectors_\"+str(year)+\".txt\"\n",
    "glove2word2vec(input_dir+file, output_dir+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "# transform sec to w2v\n",
    "year = 2010\n",
    "input_dir = '/media/sonata/MyBook/sec_embedding/sec_txt/'\n",
    "output_dir = '/media/sonata/MyBook/sec_embedding/sec_w2v/'\n",
    "for year in range(1994,2019):\n",
    "    print(year)\n",
    "    file = \"sec_vectors_\"+str(year)+\".txt\"\n",
    "    glove2word2vec(input_dir+file,output_dir+\"w2v_\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "# transform twiiter_s3 to w2v\n",
    "input_dir = '/mnt/HDD/embedding/twitter_s3_txt/'\n",
    "output_dir = '/mnt/HDD/embedding/twitter_s3_w2v/'\n",
    "for year in range(2008,2014):\n",
    "    print(year)\n",
    "    file = \"twitter_vectors_new_\"+str(year)+\".txt\"\n",
    "    glove2word2vec(input_dir+file,output_dir+\"w2v_\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "# transform ad to w2v\n",
    "input_dir = '/home/sonata/Downloads/Embedding/embedding/AD_Glove/AD_txt/'\n",
    "output_dir = '/home/sonata/Downloads/Embedding/embedding/AD_Glove/AD_w2v/'\n",
    "for year in range(2010,2017):\n",
    "    print(year)\n",
    "    file = \"AD_vectors_\"+str(year)+\".txt\"\n",
    "    glove2word2vec(input_dir+file,output_dir+\"w2v_\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n"
     ]
    }
   ],
   "source": [
    "# transform NYT to w2v\n",
    "input_dir = '/mnt/HDD/NYT_embedding/NYT_txt/'\n",
    "output_dir = '/mnt/HDD/NYT_embedding/NYT_w2v/'\n",
    "for year in range(1971,1987):\n",
    "    print(year)\n",
    "    file = \"NYT_vectors_\"+str(year)+\".txt\"\n",
    "    glove2word2vec(input_dir+file,output_dir+\"w2v_\"+file)\n",
    "for year in range(2005,2015):\n",
    "    print(year)\n",
    "    file = \"NYT_vectors_\"+str(year)+\".txt\"\n",
    "    glove2word2vec(input_dir+file,output_dir+\"w2v_\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62024, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"AD_vectors_all.txt\"\n",
    "glove2word2vec(input_dir+file,output_dir+\"w2v_\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/mnt/HDD/w2c/twitter_vectors_\"+str(year)+\".txt\"\n",
    "try:\n",
    "    w2v2010=gensim.models.KeyedVectors.load_word2vec_format(file_name,binary=False,unicode_errors='ignore')\n",
    "except:\n",
    "    w2v2010=gensim.models.KeyedVectors.load_word2vec_format(file_name,binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word1,word2,w2v):\n",
    "    try:\n",
    "        print(word1,word2,\":\",w2v.similarity(word1,word2))\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China Canada : 0.45959092115366196\n"
     ]
    }
   ],
   "source": [
    "word1 = \"China\"\n",
    "word2 = \"Canada\"\n",
    "similarity(word1,word2,w2v2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result2010 = w2v2010.accuracy(\"/home/sonata/Downloads/source-archive/word2vec/trunk/questions-words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(result):\n",
    "    for i in range(15):\n",
    "        sum_count = len(result[i]['correct'])+len(result[i]['incorrect'])\n",
    "        print(i,'\\t',len(result[i]['correct'])/sum_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.75\n",
      "1 \t 0.5277777777777778\n",
      "2 \t 0.057692307692307696\n",
      "3 \t 0.48847926267281105\n",
      "4 \t 0.7916666666666666\n",
      "5 \t 0.1813186813186813\n",
      "6 \t 0.0\n",
      "7 \t 0.8166666666666667\n",
      "8 \t 0.6727941176470589\n",
      "9 \t 0.8605263157894737\n",
      "10 \t 0.848780487804878\n",
      "11 \t 0.6084656084656085\n",
      "12 \t 0.6991341991341992\n",
      "13 \t 0.6601307189542484\n",
      "14 \t 0.6745994344957588\n"
     ]
    }
   ],
   "source": [
    "accuracy(result2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
