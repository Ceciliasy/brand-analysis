{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhon.hanzi import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_file = \"/mnt/HDD/2008/tweets.2008.txt\"\n",
    "new_file = \"/mnt/HDD/2008/tweets_new.2008.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_word(year):\n",
    "    old_file = \"/mnt/HDD/\"+str(year)+\"/tweets.\"+str(year)+\".txt\"\n",
    "    new_file = \"/mnt/HDD/\"+str(year)+\"/tweets_new.\"+str(year)+\".txt\"\n",
    "    content = []\n",
    "    with open(old_file,'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split(\" \")\n",
    "            #strip number and english puncuation\n",
    "            #line = [word.strip(\"_-&$@!#^?*+~[]{}():.,;/`\\'\\\"=0123456789\\n\") for word in line]\n",
    "            #strip chinese punctuation\n",
    "            #line = [word.strip(punctuation) for word in line]\n",
    "            # strip all symbols that are not english character\n",
    "            line = [re.sub(r\"^[^A-Za-z]+|[^A-Za-z]+$\",\"\",word) for word in line]\n",
    "            line = [word for word in line if len(word) and len(word)<20 and not word.startswith(\"http\")]\n",
    "            #line = [WordNetLemmatizer().lemmatize(word) for word in line]\n",
    "            if(len(line)>2):\n",
    "                content.append(\" \".join(line))\n",
    "            if(len(content) and len(content)%10000000 == 0):\n",
    "                with open(new_file,'a') as fw:\n",
    "                    for item in content:\n",
    "                        fw.write(item+\"\\n\")\n",
    "                print(len(content),\"save to\",new_file)\n",
    "                content = []\n",
    "    with open(new_file,'a') as fw:\n",
    "        for item in content:\n",
    "            fw.write(item+\"\\n\")\n",
    "    print(len(content),\"save to\",new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "10000000 save to /mnt/HDD/2008/tweets_new.2008.txt\n",
      "3841961 save to /mnt/HDD/2008/tweets_new.2008.txt\n"
     ]
    }
   ],
   "source": [
    "strip_word(2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "10000000 save to /mnt/HDD/2009/tweets_new.2009.txt\n",
      "8591812 save to /mnt/HDD/2009/tweets_new.2009.txt\n"
     ]
    }
   ],
   "source": [
    "strip_word(2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "10000000 save to /mnt/HDD/2010/tweets_new.2010.txt\n",
      "8529036 save to /mnt/HDD/2010/tweets_new.2010.txt\n"
     ]
    }
   ],
   "source": [
    "strip_word(2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin double parse for  2011\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "10000000 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "5251764 save to /mnt/HDD/2011/tweets_new.2011.txt\n",
      "begin double parse for  2012\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "10000000 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "4732848 save to /mnt/HDD/2012/tweets_new.2012.txt\n",
      "begin double parse for  2013\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "10000000 save to /mnt/HDD/2013/tweets_new.2013.txt\n",
      "8723338 save to /mnt/HDD/2013/tweets_new.2013.txt\n"
     ]
    }
   ],
   "source": [
    "for year in [2011,2012,2013]:\n",
    "    print(\"begin double parse for \",year)\n",
    "    strip_word(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_punctuation = \"[{}]+\".format(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdfdsdfd％s％yeah'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"^[^A-Za-z]+|[^A-Za-z]+$\",\"\",line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = [\"corvettes\"]\n",
    "lemmed = [WordNetLemmatizer().lemmatize(word) for word in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corvette']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
