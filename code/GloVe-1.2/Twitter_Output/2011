2011
VOCAB_MIN_COUNT20
*********vocabcount_1115_09:49:07
build new vocabulary
BUILDING VOCABULARY
Processed 2969187894 tokens.
Counted 74784467 unique words.
Truncating vocabulary at min count 20.
Using vocabulary of size 3371109.

*********coocur1115_10:12:57
COUNTING COOCCURRENCES
window size: 8
context: symmetric
max product: 92514853
overflow length: 285212672
Reading vocab from file "/mnt/HDD/2011/vocab_new_2011.txt"...loaded 3371109 words.
Building lookup table...table contains 1173280963 elements.
Processed 2969187779 tokens.
Writing cooccurrences to disk............18 files in total.
Merging cooccurrence files: processed 2921865286 lines.

*********shuffle_1115_10:57:25
SHUFFLING COOCCURRENCES
array size: 1912602624
Shuffling by chunks: processed 2921865286 lines.
Wrote 2 temporary file(s).
Merging temp files: processed 2921865286 lines.

*********glovetrain_1115_11:21:33
TRAINING MODEL
Read 2921865286 lines.
Initializing parameters...done.
vector size: 300
vocab size: 3371109
x_max: 10.000000
alpha: 0.750000
iter: 001, cost: 0.074659
iter: 002, cost: 0.055341
iter: 003, cost: 0.047942
iter: 004, cost: 0.043965
iter: 005, cost: 0.041455
iter: 006, cost: 0.039693
iter: 007, cost: 0.038337
iter: 008, cost: 0.037296
iter: 009, cost: 0.036450
iter: 010, cost: 0.035725
iter: 011, cost: 0.035103
iter: 012, cost: 0.034572
iter: 013, cost: 0.034125
iter: 014, cost: 0.033712
iter: 015, cost: 0.033342
*********evaluate_1115_17:12:33
Traceback (most recent call last):
  File "eval/python/evaluate.py", line 110, in <module>
    main()
  File "eval/python/evaluate.py", line 14, in main
    for line in f:
  File "/home/sonata/anaconda3/lib/python3.7/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
MemoryError

